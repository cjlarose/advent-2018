{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first I tried to use `map read` on the lines of the input, but that generates a runtime error. Positive frequencies are encoded with a leading `+` sign and Haskell refuses to parse those as one might expect. So here, we define a custom `parseInt` function that pulls off the leading `+` signs before passing the rest onto `read`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "parseInt :: String -> Int\n",
    "parseInt ('+':rest) = read rest\n",
    "parseInt str = read str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that out of the way, we compute the resulting frequency after passing through all of the additions and subtracts by just using the `sum` function on the parsed input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultingFrequency :: String -> Int\n",
    "resultingFrequency = sum . map parseInt . lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "readFile \"./inputs/1.txt\" >>= print . resultingFrequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qualified Data.Set as Set\n",
    "\n",
    "intermediateFrequencies :: [Int] -> [Int]\n",
    "intermediateFrequencies xs = 0 : f (0, xs)\n",
    "  where\n",
    "    f (currentFreq, []) = []\n",
    "    f (currentFreq, (x:xs)) = let newFreq = currentFreq + x in newFreq : f (newFreq, xs)\n",
    "\n",
    "firstDuplicate :: (Ord a) => [a] -> a\n",
    "firstDuplicate xs = f Set.empty xs\n",
    "  where\n",
    "    f visited (x:xs) = if x `Set.member` visited\n",
    "                         then x\n",
    "                         else f (Set.insert x visited) xs\n",
    "\n",
    "firstDuplicateFrequency :: String -> Int\n",
    "firstDuplicateFrequency = firstDuplicate . intermediateFrequencies . cycle . map parseInt . lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "709"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "readFile \"./inputs/1.txt\" >>= print . firstDuplicateFrequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a function `group` in `Data.List` that groups together subsequences of equal elements in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"M\",\"i\",\"ss\",\"i\",\"ss\",\"i\",\"pp\",\"i\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import Data.List (group)\n",
    "group \"Mississippi\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we apply this to a box ID after we sort its letters we'll get something like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"a\",\"b\",\"c\",\"d\",\"e\",\"g\",\"hh\",\"i\",\"j\",\"k\",\"l\",\"m\",\"o\",\"p\",\"qq\",\"r\",\"s\",\"t\",\"uu\",\"v\",\"w\",\"x\",\"y\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let boxId = \"evsialkqydurohxqpwbcugtjmh\"\n",
    "\n",
    "import Data.List (sort)\n",
    "group . sort $ boxId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can just test if there are any elements of this list that contain exactly 2 characters and test if there are any that contain exactly 3 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "any (\\x -> length x == 2) . group . sort $ boxId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "any (\\x -> length x == 3) . group . sort $ boxId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checksum :: [String] -> Int\n",
    "checksum xs = numIdsWithRepeatedChars 2 * numIdsWithRepeatedChars 3\n",
    "  where\n",
    "    numIdsWithRepeatedChars n = length . filter (any (\\x -> length x == n) . group . sort) $ xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6448"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "day2Input <- readFile \"./inputs/2.txt\"\n",
    "checksum . lines $ day2Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naively, we can test each string against every other string to count the number of differing characters. I want a function that, given a list, returns a list of pairs of elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs :: [a] -> [(a,a)]\n",
    "pairs (x:xs) = map (\\y -> (x, y)) xs ++ pairs xs\n",
    "pairs [] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,2),(1,3),(1,4),(2,3),(2,4),(3,4)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pairs [1,2,3,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can compute all of the pairs on box IDs we need to compare, we a way to calculate if two box IDs differ by exactly one character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "editDistance :: Eq a => [a] -> [a] -> Int\n",
    "editDistance xs ys = length . filter (\\(x, y) -> x /= y) $ zip xs ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "editDistance \"abc\" \"xyz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "editDistance \"abc\" \"azc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can find the unique pair of box IDs whose `editDistance` is 1. But after that, we'll need to construct the string composed of the letters shared between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharedSubsequence :: Eq a => [a] -> [a] -> [a]\n",
    "sharedSubsequence xs ys = map fst . filter (\\(x, y) -> x == y) $ zip xs ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"abde\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sharedSubsequence \"abcde\" \"abzde\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Data.List (find)\n",
    "\n",
    "commonLettersBetweenCorrectBoxIds :: [String] -> Maybe String\n",
    "commonLettersBetweenCorrectBoxIds xs = uncurry sharedSubsequence <$> pair\n",
    "  where\n",
    "    pair = find ((== 1) . uncurry editDistance) . pairs $ xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Just \"evsialkqyiurohzpwucngttmf\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "commonLettersBetweenCorrectBoxIds . lines $ day2Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first challenge is parsing the input format. The input contains \"claims\" formatted like this:\n",
    "\n",
    "```\n",
    "#1 @ 662,777: 18x27\n",
    "#2 @ 893,985: 13x10\n",
    "#3 @ 199,328: 16x16\n",
    "...\n",
    "```\n",
    "\n",
    "For Advent of Code projects in the past, I've used parser combinator libraries Parsec and Attoparsec for parsing even simple things like this. I think this time I'll just try to use a custom `Read` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data FabricClaim = FabricClaim { identifier :: Int\n",
    "                               , position :: (Int, Int)\n",
    "                               , size :: (Int, Int) } deriving (Show, Eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Data.Char (isDigit)\n",
    "\n",
    "instance Read FabricClaim where\n",
    "  readsPrec _ input =\n",
    "    let ('#':rest1) = input\n",
    "        (claimId, rest2) = span isDigit rest1\n",
    "        (' ' : '@' : ' ' : rest3) = rest2\n",
    "        (positionX, rest4) = span isDigit rest3\n",
    "        (',':rest5) = rest4\n",
    "        (positionY, rest6) = span isDigit rest5\n",
    "        (':' : ' ' : rest7) = rest6\n",
    "        (width, rest8) = span isDigit rest7\n",
    "        ('x' : rest9) = rest8\n",
    "        (height, rest10) = span isDigit rest9\n",
    "        in\n",
    "    [(FabricClaim (read claimId) (read positionX, read positionY) (read width, read height), rest10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FabricClaim {identifier = 1, position = (662,777), size = (18,27)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "read \"#1 @ 662,777: 18x27\" :: FabricClaim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FabricClaim {identifier = 1, position = (662,777), size = (18,27)},FabricClaim {identifier = 2, position = (893,985), size = (13,10)}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "read \"[#1 @ 662,777: 18x27,#2 @ 893,985: 13x10]\" :: [FabricClaim]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to fold over the list of claims. I'll need to keep track of the total area claimed so far by at least one elf as well as the total area claimed by more than one elf. Naturally, I'll want to convert every claim to a set of coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "getCoords :: FabricClaim -> Set.Set (Int, Int)\n",
    "getCoords (FabricClaim claimdId (startX, startY) (w, h)) =\n",
    "  Set.fromList [(x, y) | x <- [startX..(startX + w - 1)],\n",
    "                         y <- [startY..(startY + h - 1)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fromList [(1,2),(1,3),(1,4),(1,5),(2,2),(2,3),(2,4),(2,5),(3,2),(3,3),(3,4),(3,5)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getCoords $ FabricClaim 0 (1,2) (3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Data.List (foldl')\n",
    "\n",
    "areaInContention :: [FabricClaim] -> Set.Set (Int, Int)\n",
    "areaInContention claims =\n",
    "  let f (contended, claimed) claim = (Set.union contended . Set.intersection claimed $ getCoords claim,\n",
    "                                      Set.union claimed $ getCoords claim)\n",
    "    in\n",
    "      fst $ foldl' f (Set.empty, Set.empty) claims               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120408"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "day3Input <- readFile \"./inputs/3.txt\"\n",
    "print . length . areaInContention . map read . lines $ day3Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to find the unique claim that intersects no other claim. For this, we can iterate over every claim and check to see if its coordinate set is disjoint with the union of the coordinates of the other claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonOverlappingClaim :: [FabricClaim] -> Maybe FabricClaim\n",
    "nonOverlappingClaim xs =\n",
    "  let precomputedCoords = zip xs $ map getCoords xs\n",
    "      nonOverlapping :: (FabricClaim, Set.Set (Int, Int)) -> Bool\n",
    "      nonOverlapping x@(claim, coords) = all (Set.disjoint coords . snd) $ filter (/= x) precomputedCoords\n",
    "    in\n",
    "      fst <$> find nonOverlapping precomputedCoords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Just (FabricClaim {identifier = 1276, position = (568,851), size = (14,23)})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print . nonOverlappingClaim . map read . lines $ day3Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 4\n",
    "\n",
    "## Part 1\n",
    "\n",
    "Let's set up some data structures to represent the log data. The log entries in the input look like this:\n",
    "\n",
    "```\n",
    "[1518-11-01 00:00] Guard #10 begins shift\n",
    "[1518-11-01 00:05] falls asleep\n",
    "[1518-11-01 00:25] wakes up\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Data.Time (LocalTime)\n",
    "\n",
    "type GuardId = Int\n",
    "data GuardEvent = GuardBeginsShift GuardId | GuardFallsAsleep | GuardWakesUp deriving (Show, Eq, Ord)\n",
    "data LogEntry = LogEntry LocalTime GuardEvent deriving (Show, Eq, Ord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the `Read` instance of `LocalTime` will work for the format that appears in the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>/* Styles used for the Hoogle display in the pager */\n",
       ".hoogle-doc {\n",
       "display: block;\n",
       "padding-bottom: 1.3em;\n",
       "padding-left: 0.4em;\n",
       "}\n",
       ".hoogle-code {\n",
       "display: block;\n",
       "font-family: monospace;\n",
       "white-space: pre;\n",
       "}\n",
       ".hoogle-text {\n",
       "display: block;\n",
       "}\n",
       ".hoogle-name {\n",
       "color: green;\n",
       "font-weight: bold;\n",
       "}\n",
       ".hoogle-head {\n",
       "font-weight: bold;\n",
       "}\n",
       ".hoogle-sub {\n",
       "display: block;\n",
       "margin-left: 0.4em;\n",
       "}\n",
       ".hoogle-package {\n",
       "font-weight: bold;\n",
       "font-style: italic;\n",
       "}\n",
       ".hoogle-module {\n",
       "font-weight: bold;\n",
       "}\n",
       ".hoogle-class {\n",
       "font-weight: bold;\n",
       "}\n",
       ".get-type {\n",
       "color: green;\n",
       "font-weight: bold;\n",
       "font-family: monospace;\n",
       "display: block;\n",
       "white-space: pre-wrap;\n",
       "}\n",
       ".show-type {\n",
       "color: green;\n",
       "font-weight: bold;\n",
       "font-family: monospace;\n",
       "margin-left: 1em;\n",
       "}\n",
       ".mono {\n",
       "font-family: monospace;\n",
       "display: block;\n",
       "}\n",
       ".err-msg {\n",
       "color: red;\n",
       "font-style: italic;\n",
       "font-family: monospace;\n",
       "white-space: pre;\n",
       "display: block;\n",
       "}\n",
       "#unshowable {\n",
       "color: red;\n",
       "font-weight: bold;\n",
       "}\n",
       ".err-msg.in.collapse {\n",
       "padding-top: 0.7em;\n",
       "}\n",
       ".highlight-code {\n",
       "white-space: pre;\n",
       "font-family: monospace;\n",
       "}\n",
       ".suggestion-warning { \n",
       "font-weight: bold;\n",
       "color: rgb(200, 130, 0);\n",
       "}\n",
       ".suggestion-error { \n",
       "font-weight: bold;\n",
       "color: red;\n",
       "}\n",
       ".suggestion-name {\n",
       "font-weight: bold;\n",
       "}\n",
       "</style><span class='err-msg'>Prelude.read: no parse</span>"
      ],
      "text/plain": [
       "Prelude.read: no parse"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "read \"1518-11-03 00:29\" :: LocalTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1518-11-03 00:29:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "read \"1518-11-03 00:29:00\" :: LocalTime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like we'll have to append a `\":00\"` before we try to `read` the timestamp. No big deal. Let's try to parse the log entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Text.ParserCombinators.ReadP (ReadP, char, munch, satisfy, (<++), string)\n",
    "import qualified Text.ParserCombinators.ReadPrec as ReadPrec\n",
    "import qualified Text.Read as Read\n",
    "\n",
    "guardEvent :: ReadP GuardEvent\n",
    "guardEvent =\n",
    "  let guardBeginsShift = GuardBeginsShift <$> (string \"Guard #\" *> (read <$> munch isDigit))\n",
    "                                          <* string \" begins shift\"\n",
    "      guardFallsAsleep = GuardFallsAsleep <$ string \"falls asleep\"\n",
    "      guardWakesUp = GuardWakesUp <$ string \"wakes up\"\n",
    "    in guardBeginsShift <++ guardFallsAsleep <++ guardWakesUp\n",
    "\n",
    "instance Read GuardEvent where\n",
    "  readPrec = ReadPrec.lift guardEvent\n",
    "\n",
    "instance Read LogEntry where\n",
    "  readPrec =\n",
    "    let timestampString = (\\x -> read $ x ++ \":00\") <$> (char '[' *> munch (/= ']')) <* char ']'\n",
    "      in ReadPrec.lift $ LogEntry <$> (timestampString <* char ' ') <*> guardEvent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogEntry 1518-11-01 00:00:00 (GuardBeginsShift 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "read \"[1518-11-01 00:00] Guard #10 begins shift\" :: LogEntry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogEntry 1518-11-01 00:05:00 GuardFallsAsleep"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "read \"[1518-11-01 00:05] falls asleep\" :: LogEntry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogEntry 1518-11-01 00:25:00 GuardWakesUp"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "read \"[1518-11-01 00:25] wakes up\" :: LogEntry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can parse the log entries, we can move on to computing the times that each guard slept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data OnDutyNap = OnDutyNap GuardId LocalTime LocalTime deriving Show\n",
    "\n",
    "napper :: OnDutyNap -> GuardId\n",
    "napper (OnDutyNap guardId _ _) = guardId\n",
    "\n",
    "import Data.Time.LocalTime (LocalTime(..), TimeOfDay(..))\n",
    "\n",
    "napDurationInMinutes :: OnDutyNap -> Int\n",
    "napDurationInMinutes (OnDutyNap _ (LocalTime _ (TimeOfDay _ mStart _)) (LocalTime _ (TimeOfDay _ mEnd _))) =\n",
    "  mEnd - mStart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "napDurationInMinutes $ OnDutyNap 10 (read \"1518-11-01 00:05:00\") (read \"1518-11-01 00:25:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractNaps :: [LogEntry] -> [OnDutyNap]\n",
    "extractNaps =\n",
    "  let isNapEntry (LogEntry _ GuardFallsAsleep) = True\n",
    "      isNapEntry (LogEntry _ GuardWakesUp) = True\n",
    "      isNapEntry _ = False\n",
    "      getNaps guardId [] = []\n",
    "      getNaps guardId (LogEntry start GuardFallsAsleep : LogEntry end GuardWakesUp : xs) =\n",
    "        OnDutyNap guardId start end : getNaps guardId xs\n",
    "      extract [] = []\n",
    "      extract (LogEntry _ (GuardBeginsShift guardId):xs) =\n",
    "        let (napEntries, remainingEntries) = span isNapEntry xs\n",
    "          in getNaps guardId napEntries ++ extract remainingEntries\n",
    "    in extract . sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OnDutyNap 10 1518-11-01 00:05:00 1518-11-01 00:25:00,OnDutyNap 10 1518-11-01 00:28:00 1518-11-01 00:34:00]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "extractNaps [LogEntry (read \"1518-11-01 00:00:00\") (GuardBeginsShift 10)\n",
    "            ,LogEntry (read \"1518-11-01 00:05:00\") GuardFallsAsleep\n",
    "            ,LogEntry (read \"1518-11-01 00:25:00\") GuardWakesUp\n",
    "            ,LogEntry (read \"1518-11-01 00:28:00\") GuardFallsAsleep\n",
    "            ,LogEntry (read \"1518-11-01 00:34:00\") GuardWakesUp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For part 1, we'll need to get the guard that sleeps the most, and then find the minute that he's asleep for most often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Data.List (maximumBy, groupBy, sortBy)\n",
    "import Data.Ord (comparing)\n",
    "\n",
    "sleepiestGuard :: [OnDutyNap] -> GuardId\n",
    "sleepiestGuard =\n",
    "  let totalMinutesSleeping :: [OnDutyNap] -> Int\n",
    "      totalMinutesSleeping = sum . map napDurationInMinutes\n",
    "    in napper . head .\n",
    "       maximumBy (\\a b -> compare (totalMinutesSleeping a) (totalMinutesSleeping b)) .\n",
    "       groupBy (\\a b -> napper a == napper b) .\n",
    "       sortBy (\\a b -> compare (napper a) (napper b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sleepiestGuard [OnDutyNap 10 (read \"1518-11-01 00:05:00\") (read \"1518-11-01 00:25:00\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sleepiestGuard [OnDutyNap 10 (read \"1518-11-01 00:05:00\") (read \"1518-11-01 00:25:00\")\n",
    "               ,OnDutyNap 11 (read \"1518-11-01 00:32:00\") (read \"1518-11-01 00:55:00\")\n",
    "               ,OnDutyNap 12 (read \"1518-11-01 00:01:00\") (read \"1518-11-01 00:02:00\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "minutesSleeping :: OnDutyNap -> [Int]\n",
    "minutesSleeping (OnDutyNap _ (LocalTime _ (TimeOfDay _ mStart _)) (LocalTime _ (TimeOfDay _ mEnd _))) =\n",
    "  [mStart..mEnd-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8,9,10,11,12,13,14,15,16,17,18,19,20,21]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "minutesSleeping $ OnDutyNap 12 (read \"1518-11-01 00:08:00\") (read \"1518-11-01 00:22:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qualified Data.Ord\n",
    "import Data.List (sortOn)\n",
    "\n",
    "mode :: Ord a => [a] -> (Int, a)\n",
    "mode = head . sortOn Data.Ord.Down . map (\\xs -> (length xs, head xs)) . group . sort\n",
    "\n",
    "mostFrequentMinuteSpentSleeping :: [OnDutyNap] -> (Int, Int)\n",
    "mostFrequentMinuteSpentSleeping = mode . concatMap minutesSleeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,24)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mostFrequentMinuteSpentSleeping\n",
    " [OnDutyNap 10 (read \"1518-11-01 00:05:00\") (read \"1518-11-01 00:25:00\")\n",
    " ,OnDutyNap 10 (read \"1518-11-01 00:30:00\") (read \"1518-11-01 00:55:00\")\n",
    " ,OnDutyNap 10 (read \"1518-11-01 00:24:00\") (read \"1518-11-01 00:29:00\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"73 * 44 = 3212\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "day4Input <- readFile \"./inputs/4.txt\"\n",
    "let entries :: [LogEntry]\n",
    "    entries = sort . map read . lines $ day4Input\n",
    "    naps = extractNaps entries\n",
    "    guardId = sleepiestGuard naps\n",
    "    (_,minute) = mostFrequentMinuteSpentSleeping (filter ((== guardId) . napper) naps)\n",
    "  in show guardId ++ \" * \" ++ show minute ++ \" = \" ++ show (guardId * minute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"191 * 26 = 4966\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let entries = sort . map read . lines $ day4Input\n",
    "    naps = extractNaps entries\n",
    "    (guardId,(_,minute)) = maximumBy (\\(_,a) (_,b) -> compare a b) . \n",
    "      map (\\xs -> (napper . head $ xs, mostFrequentMinuteSpentSleeping xs)) .\n",
    "      groupBy (\\a b -> napper a == napper b) . sortOn napper $ naps\n",
    "  in show guardId ++ \" * \" ++ show minute ++ \" = \" ++ show (guardId * minute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 5\n",
    "\n",
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Data.Bits (xor)\n",
    "import Data.Char (ord)\n",
    "\n",
    "type Polymer = (String,String)\n",
    "\n",
    "toPolymer :: String -> Polymer\n",
    "toPolymer xs = ([],xs)\n",
    "\n",
    "fromPolymer :: Polymer -> String\n",
    "fromPolymer (xs,[]) = reverse xs\n",
    "\n",
    "reactPolymer :: Polymer -> Polymer\n",
    "reactPolymer (xs,[]) = (xs,[])\n",
    "reactPolymer (xs,[y]) = (y:xs,[])\n",
    "reactPolymer ([],y:z:xs) | (ord y) `xor` 32 == (ord z) = reactPolymer ([], xs)\n",
    "                         | otherwise = reactPolymer (y:[], z:xs)\n",
    "reactPolymer (x:xs,y:z:ys) | (ord y) `xor` 32 == (ord z) = reactPolymer (xs, x:ys)\n",
    "                           | otherwise = reactPolymer (y:x:xs,z:ys)\n",
    "        \n",
    "collapseAll :: String -> String\n",
    "collapseAll = fromPolymer . reactPolymer . toPolymer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"dabCBAcaDA\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "collapseAll \"dabAcCaCBAcCcaDA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11042"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "day5Input <- readFile \"./inputs/5.txt\"\n",
    "length . collapseAll . head . lines $ day5Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6872"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import Data.Char (toUpper)\n",
    "import Data.List (minimumBy)\n",
    "\n",
    "let units = ['a'..'z']\n",
    "    originalPolymer = head . lines $ day5Input\n",
    "    candidates = map (\\x -> filter (\\y -> y /= x && y /= toUpper x) originalPolymer) units\n",
    "    reactedCandidates = map collapseAll candidates\n",
    "    shortest = minimumBy (\\a b -> compare (length a) (length b)) reactedCandidates\n",
    "  in length shortest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 6\n",
    "\n",
    "Fortunately, parsing the input format is a bit easier for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Text.ParserCombinators.ReadP (many, eof, readP_to_S)\n",
    "\n",
    "listOfCoordinates :: ReadP [(Int, Int)]\n",
    "listOfCoordinates =\n",
    "  let coordinate = (\\a b -> (read a, read b)) <$> munch isDigit <* string \", \" <*> munch isDigit\n",
    "      in (many $ coordinate <* char '\\n') <* eof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(45,315),(258,261),(336,208),(160,322),(347,151),(321,243),(232,148),(48,202),(78,161),(307,230),(170,73),(43,73),(74,248),(177,296),(330,266),(314,272),(175,291),(75,142),(278,193),(279,337),(228,46),(211,164),(131,100),(110,338),(336,338),(231,353),(184,213),(300,56),(99,231),(119,159),(180,349),(130,193),(308,107),(140,40),(222,188),(356,44),(73,107),(304,313),(199,238),(344,158),(49,225),(64,117),(145,178),(188,265),(270,215),(48,181),(213,159),(174,311),(114,231),(325,162)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "day6Input <- readFile \"./inputs/6.txt\"\n",
    "let [(parsed,_)] = readP_to_S listOfCoordinates day6Input\n",
    "  in print parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start off by giving a definition of the manhattan distance between two points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattanDistance :: (Int, Int) -> (Int, Int) -> Int\n",
    "manhattanDistance (x1, y1) (x2, y2) = abs (x2 - x1) + abs (y2 - y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll want to be able to calculate the closest point out of a list of points. If a point is equally close to two or more points, we'll return `Nothing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "closestPoint :: [(Int, Int)] -> (Int, Int) -> Maybe (Int, Int)\n",
    "closestPoint xs x =\n",
    "  let distances = sortOn snd $ map (\\y -> (y, manhattanDistance y x)) xs\n",
    "      (closest:_) = groupBy (\\a b -> snd a == snd b) distances\n",
    "    in if length closest == 1 then Just (fst . head $ closest) else Nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Just (1,1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Just (1,1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Just (3,4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Nothing"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let examplePoints = [(1, 1), (1, 6), (8, 3), (3, 4), (5, 5), (8, 9)]\n",
    "closestPoint examplePoints (1,1)\n",
    "closestPoint examplePoints (2,2)\n",
    "closestPoint examplePoints (3,3)\n",
    "closestPoint examplePoints (5,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find the sizes around regions around our given points. My stategy for determining when we're in an \"infinite\" region will be to expand the group from the given point step-by-step until we generate a coordinate that is not closer to any point than the point that generated it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data Region = FiniteRegion (Set.Set (Int, Int)) | InfiniteRegion deriving Show\n",
    "\n",
    "closerToAnyPoint :: [(Int, Int)] -> (Int, Int) -> (Int, Int) -> Bool\n",
    "closerToAnyPoint xs a b =\n",
    "  let ds x = map (manhattanDistance x) xs\n",
    "    in any ((>) 0) $ zipWith (-) (ds a) (ds b)\n",
    "\n",
    "regionAround :: [(Int, Int)] -> (Int, Int) -> Region\n",
    "regionAround ps p0 =\n",
    "  let expand :: Region -> Set.Set (Int, Int) -> (Int, Int) -> (Region, Set.Set (Int, Int))\n",
    "      expand InfiniteRegion vs p = (InfiniteRegion, Set.insert p vs)\n",
    "      expand (FiniteRegion rs) vs p@(x,y)\n",
    "        | p `Set.member` vs || closestPoint ps p /= Just p0 = (FiniteRegion rs, Set.insert p vs)\n",
    "        | p /= p0 && not (closerToAnyPoint ps p p0) = (InfiniteRegion, Set.insert p vs)\n",
    "        | otherwise = let (r0, v0) = (FiniteRegion $ Set.insert p rs, Set.insert p vs)\n",
    "                          (r1, v1) = expand r0 v0 (x + 1, y)\n",
    "                          (r2, v2) = expand r1 v1 (x - 1, y)\n",
    "                          (r3, v3) = expand r2 v2 (x, y + 1)\n",
    "                          (r4, v4) = expand r3 v3 (x, y - 1)\n",
    "                        in (r4, v4)\n",
    "    in fst $ expand (FiniteRegion Set.empty) Set.empty p0\n",
    "\n",
    "regions :: [(Int, Int)] -> [Region]\n",
    "regions xs = map (regionAround xs) xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[InfiniteRegion,InfiniteRegion,InfiniteRegion,FiniteRegion (fromList [(2,3),(2,4),(3,2),(3,3),(3,4),(3,5),(4,2),(4,3),(4,4)]),FiniteRegion (fromList [(4,5),(4,6),(4,7),(4,8),(5,2),(5,3),(5,4),(5,5),(5,6),(5,7),(5,8),(6,4),(6,5),(6,6),(6,7),(7,5),(7,6)]),InfiniteRegion]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "regions examplePoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, among the finite regions, we want the largest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionSize :: Region -> Int\n",
    "regionSize (FiniteRegion rs) = Set.size rs\n",
    "\n",
    "isFinite :: Region -> Bool\n",
    "isFinite InfiniteRegion = False\n",
    "isFinite (FiniteRegion _) = True\n",
    "\n",
    "largestRegion :: [Region] -> Region\n",
    "largestRegion = maximumBy (\\a b -> compare (regionSize a) (regionSize b)) . filter isFinite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3894"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let [(coords,_)] = readP_to_S listOfCoordinates day6Input\n",
    "  in print . regionSize . largestRegion . regions $ coords"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Haskell",
   "language": "haskell",
   "name": "haskell"
  },
  "language_info": {
   "codemirror_mode": "ihaskell",
   "file_extension": ".hs",
   "name": "haskell",
   "pygments_lexer": "Haskell",
   "version": "8.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
